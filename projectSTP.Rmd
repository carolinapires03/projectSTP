---
title: ' Time Series and Forecasting Project'
author: "Bárbara Galiza 202408654; Carolina Pires 202408704; Mariia Zhokhova 202408799"
subtitle: Analyse time series data
output:
  html_document:
    df_print: paged
institute: Faculdade de Ciências, Universidade do Porto
---

```{r}
library(tidyverse)
library(lubridate)
library(ggplot2)
library(forecast)
library(tseries)
library(ggcorrplot)
library(scales)
library(astsa)
library(seasonal)
```

# Exploratory Data Analysis

```{r}
dataset <- read.csv("amazon_with_date.csv")
```

```{r}
head(dataset)
```

```{r}
summary(dataset)
```

```{r}
colSums(is.na(dataset))
```

```{r}
duplicados <- dataset[duplicated(dataset), ]
cat("Number of duplicate rows: ", nrow(duplicados), "\n")
```

```{r}
dataset_sem_duplicados <- dataset %>% distinct()
```

```{r}
cat("Número total de linhas após remover duplicados: ", nrow(dataset_sem_duplicados), "\n")
```

```{r}
dataset <- dataset_sem_duplicados
```

```{r}
dataset <- dataset %>%
  mutate(year = as.integer(year))
```

```{r}
str(dataset) 
```

#### Aggregate data by year

```{r}
annual_data <- dataset %>%
  group_by(year) %>%
  summarise(total_fires = sum(fires, na.rm = TRUE))
```

```{r}
head(annual_data)
```

```{r}
summary(annual_data$total_fires)
```

```{r}
ggplot(annual_data, aes(x = year, y = total_fires)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Annual Number of Forest Fires in Brazil",
       x = "year", y = "Number of fires") +
  theme_minimal()
```

```{r}
estados_unicos <- unique(dataset$state)

cat("Estados presentes no dataset:\n")
print(estados_unicos)
```
```{r}
cat("Total number of unique states:", length(estados_unicos), "\n")

frequencia_estados <- dataset %>%
  count(state) %>%
  arrange(desc(n))

cat("Frequency of occurrences by state:\n")
print(frequencia_estados)
```
```{r}
incendios_por_estado <- dataset %>%
  group_by(state) %>%
  summarise(total_incendios = sum(fires, na.rm = TRUE)) %>%
  arrange(desc(total_incendios))

cat("Total number of fires per state:\n")
print(incendios_por_estado)
```
```{r}
ggplot(incendios_por_estado, aes(x = reorder(state, -total_incendios), y = total_incendios)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  labs(title = "Total number of fires per state",
       x = "States", y = "Number of fires") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


```{r}
fires_ts <- ts(annual_data$total_fires, start = min(annual_data$year), frequency = 1)
```

```{r}
plot(fires_ts, main = "Time Series of Forest Fires in Brazil",
     xlab = "Year", ylab = "Number of fires", col = "blue", lwd = 2)
```
## State chosen: Mato Grosso do Sul

```{r}
mato_grosso_data <- dataset %>%
  filter(state == "MATO GROSSO DO SUL") %>%
  arrange(year, month)
```

```{r}
head(mato_grosso_data)
```

```{r}
ts_mato_grosso <- ts(mato_grosso_data$fires, 
                     start = c(min(mato_grosso_data$year), min(mato_grosso_data$month)), 
                     frequency = 12)
```


```{r}
plot(ts_mato_grosso, main = "Fire Time Series - Mato Grosso",
     xlab = "Year", ylab = "Number of fires", col = "blue", lwd = 2)
```
#### Aggregate data annually

```{r}
annual_mato_grosso <- mato_grosso_data %>%
  group_by(year) %>%
  summarise(total_fires = sum(fires, na.rm = TRUE))
```

```{r}
print(annual_mato_grosso)
```

```{r}
ts_mato_grosso_annual <- ts(annual_mato_grosso$total_fires, 
                            start = min(annual_mato_grosso$year), 
                            frequency = 1)
```

```{r}
plot(ts_mato_grosso_annual, main = "Annual Time Series of Fires - Mato Grosso",
     xlab = "Ano", ylab = "Number of fires", col = "darkblue", lwd = 2)
```

### Autocorrelation analysis

- Monthly data
```{r}
acf(ts_mato_grosso, main = "Autocorrelation Function (ACF)")
pacf(ts_mato_grosso, main = "Partial Autocorrelation Function (PACF)")
```

```{r}
mato_grosso_agg <- mato_grosso_data %>%
  group_by(year) %>%
  summarise(total_fires = sum(fires, na.rm = TRUE))
```

```{r}
ggplot(mato_grosso_agg, aes(x = year, y = total_fires)) +
  geom_line(color = "blue", size = 1) +
  geom_point(color = "red", size = 2) +
  labs(title = "Annual Evolution of Forest Fires - Mato Grosso",
       x = "Year", y = "Number of Fires") +
  theme_minimal()
```



```{r}
mato_grosso_agg <- mato_grosso_agg %>%
  mutate(change = c(NA, diff(total_fires))) 

ggplot(mato_grosso_agg, aes(x = year, y = change)) +
  geom_line(color = "purple", size = 1) +
  labs(title = "Annual Variation in the Number of Fires - Mato Grosso",
       x = "Year", y = "Change in the Number of Fires") +
  theme_minimal()
```

```{r}
trend_model <- lm(total_fires ~ year, data = annual_mato_grosso)

summary(trend_model)

annual_mato_grosso <- annual_mato_grosso %>%
  mutate(
    trend = predict(trend_model),       
    residuals = total_fires - trend     
  )

library(ggplot2)
ggplot(annual_mato_grosso, aes(x = year)) +
  geom_line(aes(y = total_fires, color = "Observed"), size = 1) +
  geom_line(aes(y = trend, color = "Trend"), linetype = "dashed", size = 1) +
  labs(title = "Observed vs Trend - Annual Fires in Mato Grosso",
       x = "Year", y = "Number of Fires") +
  scale_color_manual(name = "Legend", values = c("Observed" = "blue", "Trend" = "red")) +
  theme_minimal()

ggplot(annual_mato_grosso, aes(x = year, y = residuals)) +
  geom_line(color = "purple", size = 1) +
  labs(title = "Residuals of Annual Fires - Mato Grosso",
       x = "Year", y = "Residuals") +
  theme_minimal()
```
### seasonality 

```{r}
ggplot(mato_grosso_data, aes(x = as.factor(month), y = fires)) +
  geom_boxplot() +
  labs(title = "Monthly Seasonality - Mato Grosso", x = "Month", y = "Number of Fires") +
  theme_minimal()
```
```{r}
monthplot(ts_mato_grosso)
```
```{r}
seasonplot(ts_mato_grosso)

```

### Seasonal Moving Averages

```{r}
moving_avg <- mato_grosso_data %>%
  arrange(year, month) %>%
  mutate(moving_avg = zoo::rollmean(fires, k = 12, fill = NA))

ggplot(moving_avg, aes(x = as.Date(paste(year, month, 1, sep = "-")), y = moving_avg)) +
  geom_line(color = "blue") +
  labs(title = "12-Month Moving Average", x = "Date", y = "Moving Average of Fires") +
  theme_minimal()
```


```{r}
dummies_model <- tslm(ts_mato_grosso ~ trend + season)
summary(dummies_model)

autoplot(ts_mato_grosso, series="Data") +
  autolayer(fitted(dummies_model), series="Fitted") +
  xlab("Year") + ylab("Number of Fires") +
  ggtitle("Fitted Trend and Seasonality - Mato Grosso")

plot(residuals(dummies_model), main = "Detrended Desasonalized Data - Mato Grosso", type="l", col="blue")
```
```{r}
# Fourier Series for Seasonality
fourier_model <- tslm(ts_mato_grosso ~ trend + fourier(ts_mato_grosso, K=2))
summary(fourier_model)

autoplot(ts_mato_grosso, series="Data") +
  autolayer(fitted(fourier_model), series="Fitted") +
  xlab("Year") + ylab("Number of Fires") +
  ggtitle("Fitted Fourier Model - Mato Grosso")

plot(residuals(fourier_model), main = "Detrended Desasonalized Data - Fourier - Mato Grosso", type="l", col="blue")
seasonplot(residuals(fourier_model))
```
```{r}
# Seasonal Differencing
plot(ts_mato_grosso, main="Original Series", type="l", col="blue")
plot(diff(ts_mato_grosso, 12), main="Seasonally Differenced Series", type="l", col="red")
monthplot(diff(ts_mato_grosso, 12))
```

```{r}
# Removing Both Trend and Seasonality
plot(ts_mato_grosso, main="Original Series", type="l", col="blue")
plot(diff(diff(ts_mato_grosso), 12), main="Trend and Seasonally Differenced Series", type="l", col="red")
acf(diff(diff(ts_mato_grosso), 12), main="ACF of Trend and Seasonally Differenced Series")
```

```{r}
# STL Decomposition
mato_grosso_stl_per <- stl(ts_mato_grosso, s.window="periodic")
mato_grosso_stl <- stl(ts_mato_grosso, s.window=13)
plot(mato_grosso_stl_per)
plot(mato_grosso_stl)
```

```{r}
# Extracting Time Series Components
head(mato_grosso_stl_per$time.series, 24)
head(mato_grosso_stl$time.series, 24)
```

```{r}
# Correlation Behavior in Remainder
acf(ts_mato_grosso, main="ACF of Original Series")
acf(mato_grosso_stl$time.series[,3], main="ACF of Remainder")
```

### Dividing the data into training and test

```{r}
train_mato_grosso <- window(ts_mato_grosso, end = c(2015, 12)) 
test_mato_grosso <- window(ts_mato_grosso, start = c(2016, 1))
```

```{r}
plot(train_mato_grosso, 
     main = "Training Set - Mato Grosso", 
     ylab = "Number of fires", 
     xlab = "Year", 
     col = "darkgreen", 
     lwd = 2)

plot(test_mato_grosso, 
     main = "Test Set - Mato Grosso", 
     ylab = "Number of fires", 
     xlab = "Year", 
     col = "orange", 
     lwd = 2)
```

### Modelo ARIMA


Apply logarithm because of hetecedasticity:
```{r}
library(forecast)
shift_value <- 1 - min(train_mato_grosso)
train_mato_grosso_shifted <- train_mato_grosso + shift_value

ly = log(train_mato_grosso_shifted)
plot(ly, 
     main = "Training Set (logged) - Mato Grosso", 
     ylab = "Number of fires", 
     xlab = "Year", 
     col = "darkgreen", 
     lwd = 2)

# Calculate the optimal lambda for Box-Cox transformation
lambda <- BoxCox.lambda(train_mato_grosso_shifted)

# Apply the Box-Cox transformation
by <- BoxCox(train_mato_grosso_shifted, lambda)

# Plot the transformed time series
plot(
  by,
  main = "Training Set (BoxCox) - Mato Grosso",
  ylab = "Number of Fires",
  xlab = "Year",
  col = "darkgreen",
  lwd = 2
)
```
ADF and KPSS tests
```{r}
deseasonalized_ly <- final(seas(ly)) 
adf_test_train <- adf.test(deseasonalized_ly, alternative = "stationary")
cat("ADF Test - p-value:", adf_test_train$p.value, "\n")
if (adf_test_train$p.value < 0.05) {
  cat("The series is stationary based on the ADF test.\n")
} else {
  cat("The series is not stationary based on the ADF test.\n")
}

kpss_test_train <- kpss.test(deseasonalized_ly, null = "Level")
cat("KPSS Test - p-value:", kpss_test_train$p.value, "\n")
if (kpss_test_train$p.value < 0.05) {
  cat("The series is NOT stationary based on the KPSS test.\n")
} else {
  cat("The series is stationary based on the KPSS test.\n")
}
```
The tests indicate stationarity. Use ndiffs and nsdiffs:
```{r}
nsdiffs(ly)
ndiffs(ly)
```

Results indicare series is not stationary, needs differiencing. d = 0, D = 1.
```{r}
dly1 = diff(ly,1)
dly12 = diff(ly,12)
dly12_1 = diff(diff(ly,12),1)
```

```{r}
maxlag <- 48
par(mfrow=c(3,4), mar=c(3,3,4,2))

plot(ly, main = expression("log(y)"))
plot(dly1, main = expression(paste(Delta, "log(y)")))
plot(dly12, main = expression(paste(Delta[12], "log(y)")))
plot(dly12_1, main = expression(paste(Delta, Delta[12], "log(y)")))

Acf(ly, type='correlation', lag=maxlag, ylab="", main=expression(paste("ACF for log(y)")))
Acf(dly1, type='correlation', lag=maxlag, na.action=na.omit, ylab="", main=expression(paste("ACF for ", Delta,"log(y)")))
Acf(dly12, type='correlation', lag=maxlag, na.action=na.omit, ylab="", main=expression(paste("ACF for ", Delta[12], "log(y)")))
Acf(dly12_1, type='correlation', lag=maxlag, na.action=na.omit, ylab="", main=expression(paste("ACF for ", Delta, Delta[12], "log(y)")))

Acf(ly, type='partial', lag=maxlag, na.action=na.omit, ylab="", main=expression(paste("PACF for log(y)")))
Acf(dly1, type='partial', lag=maxlag, na.action=na.omit, ylab="", main=expression(paste("PACF for ", Delta, "log(y)")))
Acf(dly12, type='partial', lag=maxlag, na.action=na.omit, ylab="", main=expression(paste("PACF for ", Delta[12], "log(y)")))
Acf(dly12_1, type='partial', lag=maxlag, na.action=na.omit, ylab="", main=expression(paste("PACF for ", Delta,Delta[12], "log(y)")))
```

Although the ndiffs and nsdiffs tests indicated d = 0 and D = 1, the ACF and PACF of D=1 and d=1 shows a more stationary series. So we will test for both d = 1 and d = 0. For the MA and AR components, for the d = 0 we propose q = 0, p = 1 or 2, P = 1, given the significant lag 12 at the PACF, and Q = 0. For d = 1, we propose q = 1, p = 0, Q = 1 (lag 12 on ACF) and P = 1. Also, s = 12.

Models SARIMA(p,d,q)x(P,D,Q)s to try:
SARIMA(1,0,0)x(1,1,0)12
SARIMA(2,0,0)x(1,1,0)12
SARIMA(0,1,1)x(1,1,1)12

```{r}

m1=sarima(ly,1,0,0,1,1,0,12)
```
The residuals from model 1 show autocorrelation
```{r}
m2=sarima(ly,2,0,0,1,1,0,12)
```
Seems like a good fit, with all the p-values from Ljung-Box being above 0.05, meaning the residuals are independent, and the ACF of residuals show they are mostly uncorrelated.
```{r}
m3=sarima(ly,0,1,1,1,1,1,12)
```
Not a good fit given the Ljung-Box statistic.

M2 was the best fit. We must investigate if the parameters are significant:
```{r}
m2
```
Constant is not significant

```{r}
m21 = sarima(ly, 2, 0, 0, 1, 1, 0, 12, no.constant = TRUE)
```
```{r}
m21
```
Now all the parameters are significant.
```{r}
acf2(m21$fit$residuals)
```
There is still some correlation left on the PACF, lets try variations of m21.
```{r}
m22 = sarima(ly, p = 3, d = 0, q = 0, P = 1, D = 1, Q = 0, S = 12, no.constant = TRUE)
acf2(m22$fit$residuals)
```
AR3 not significant. Lets try q = 1

```{r}
m23 = sarima(ly, p = 2, d = 0, q = 1, P = 1, D = 1, Q = 0, S = 12, no.constant = TRUE)
acf2(m23$fit$residuals)
```
Still the same problem with PACF and non significant coefficients. Since the AR2 is the one with the greater p-value, lets try p=1 and q=1.
```{r}
m24 = sarima(ly, p = 1, d = 0, q = 1, P = 1, D = 1, Q = 0, S = 12, no.constant = TRUE)
acf2(m24$fit$residuals)
```
All the parameters are significant, and the Ljung-Box p-values are mostly above the line. The PACF and ACF look similar to the m21 ones, so we can consider m24 as a good competitor.

The models which meet residual white-noise conditions and had all parameters significant are then m21 and m24:

```{r}
m21
```
```{r}
m24
```
The AIC, AICc and BIC of m24 are lower than m21, which would make it the best model. However, we still need to compare the models based on the quality of their forecasts.

```{r}
m21_arima <- Arima(ly, order = c(2, 0, 0), seasonal=list(order=c(1,1,0), period=12), include.constant = FALSE)
m24_arima <- Arima(ly, order = c(1, 0, 1), seasonal=list(order=c(1,1,0), period=12), include.constant = FALSE)

hmax <- 23
m21.f.h <- forecast(m21_arima, h=hmax)
m24.f.h <- forecast(m24_arima, h=hmax)
```

```{r}
test_mato_grosso_shifted <- test_mato_grosso + shift_value
log_test <- log(test_mato_grosso_shifted)

m21.f.h.acc = accuracy(m21.f.h, log_test)
m24.f.h.acc = accuracy(m24.f.h, log_test)
m21.f.h.acc
```
```{r}
m24.f.h.acc
```

The two models performed similarly on the training set, but m21 shows a clear advantage on the test set results in all the most relevant metrics (RMSE, MAE, MAPE, MASE).
NOTE: These are logged values, so they work for comparing the models but not for interpreting the direct effect on number of fires.

Final model: SARIMA(2,0,0)x(1,1,0)12 with no constant (full formula on the report).

### FORECASTING

Forecast the next 23 months via sarima.for method 
NO CROSS-VALIDATION
```{r}
log_test_mato_grosso <- log(test_mato_grosso)
forecast_m21 <- sarima.for(ly, n.ahead = length(log_test_mato_grosso), p = 2, d = 0, q = 0, P = 1, D = 1, Q = 0, S = 12, no.constant = TRUE)
```
```{r}
#get data in the original shape (non-transformed)
forecast_values <- exp(forecast_m21$pred) - shift_value
test_values <- test_mato_grosso
```

95% prediction intervals
```{r}
#Lower and upper bounds for 95% intervals
lowerB <- forecast_m21$pred - 1.96 * forecast_m21$se
upperB <- forecast_m21$pred + 1.96 * forecast_m21$se

#cat("The upper bounds for our forward pred are: ", upperB, "\n")
#cat("The lower bounds for our forward pred are: ", lowerB, "\n")

```

```{r}
#get bounds in a nn-transformed form
lower_bound <- exp(lowerB) - shift_value
upper_bound <- exp(upperB) - shift_value
```


Plotting forecasted and actual data
```{r}
library(ggplot2)

#Create a comparison table
comparison_table <- data.frame(
  Date = seq(as.Date("2016-01-01"), by = "month", length.out = length(test_values)),
  Actual = test_values,
  Forecasted = forecast_values,
  Lower_95 = lower_bound,  # Lower bound of the 95% interval
  Upper_95 = upper_bound,  # Upper bound of the 95% interval
  Error = test_values - forecast_values,  # Error: Actual - Forecast
  Absolute_Error = abs(test_values - forecast_values),  # Absolute Error
  Percentage_Error = (abs(test_values - forecast_values) / test_values) * 100  # Percentage Error
)
comparison_table$Within_95_Interval <- with(comparison_table, Actual >= Lower_95 & Actual <= Upper_95)

#Create a plot

ggplot(comparison_table, aes(x = Date)) +
  geom_line(aes(y = log(Actual + shift_value), color = "Actual"), size = 1) +
  geom_line(aes(y = log(Forecasted + shift_value), color = "Forecast"), size = 1, linetype = "dashed") +
  geom_ribbon(aes(ymin = log(Lower_95 + shift_value), ymax = log(Upper_95 + shift_value)), fill = "lightblue", alpha = 0.5) +
  labs(
    title = "LOG SCALE: Actual vs Forecasted Values with 95% Prediction Intervals",
    x = "Date",
    y = "LOG(Number of fires)"
  ) +
  scale_color_manual(values = c("Actual" = "blue", "Forecast" = "red")) +
  theme_minimal() +
  theme(legend.title = element_blank()) 

ggplot(comparison_table, aes(x = Date)) +
  geom_line(aes(y = Actual, color = "Actual"), size = 1) +
  geom_line(aes(y = Forecasted, color = "Forecast"), size = 1, linetype = "dashed") +
  geom_ribbon(aes(ymin = Lower_95, ymax = Upper_95), fill = "lightblue", alpha = 0.5) +
  labs(
    title = "Actual vs Forecasted Values with 95% Prediction Intervals",
    x = "Date",
    y = "Number of fires"
  ) +
  scale_color_manual(values = c("Actual" = "blue", "Forecast" = "red")) +
  theme_minimal() +
  theme(legend.title = element_blank())  

#Create a plot - without intervals
ggplot(comparison_table, aes(x = Date)) +
  geom_line(aes(y = Actual, color = "Actual"), size = 1) +
  geom_line(aes(y = Forecasted, color = "Forecast"), size = 1, linetype = "dashed") +
  labs(
    title = "Actual vs Forecasted Values with 95% Prediction Intervals",
    x = "Date",
    y = "Number of fires"
  ) +
  scale_color_manual(values = c("Actual" = "blue", "Forecast" = "red")) +
  theme_minimal() +
  theme(legend.title = element_blank()) 

# Print the comparison table
print(comparison_table)


mae <- mean(comparison_table$Absolute_Error)
rmse <- sqrt(mean(comparison_table$Error^2))
mape <- mean(comparison_table$Percentage_Error)
medae <- median(comparison_table$Error)
ss_total <- sum((comparison_table$Actual - mean(comparison_table$Actual))^2)
ss_residual <- sum((comparison_table$Actual - comparison_table$Forecasted)^2)
r_squared <- 1 - (ss_residual / ss_total)
bias <- mean(comparison_table$Forecasted - comparison_table$Actual)
naive_forecast <- c(NA, head(comparison_table$Actual, -1))  # Naive forecast: previous value
mae_naive <- mean(abs(comparison_table$Actual - naive_forecast), na.rm = TRUE)  # MAE of naive forecast
mase <- mae / mae_naive

# Creating a dataframe for evaluation statistics
evaluation_df <- data.frame(
  Metric = c("MAE", "RMSE", "MAPE", "MedAE", "R-Squared", "Bias","MASE"),
  Value = c(mae, rmse, mape, medae, r_squared, bias,mase)
)

print(evaluation_df)
```



Forecasting the last 23 months
CROSS-VALIDATION 23 months with 1-step ahead - Expanding windows


```{r}
#Applying log for original data
shift_value <- 1 - min(ts_mato_grosso)
ts_mato_grosso_shifted <- ts_mato_grosso + shift_value
log_ts <- log(ts_mato_grosso_shifted)

# Setting the size of the training and test set
train_size <- length(log_ts) - length(test_mato_grosso)  

# Storing the forecast errors, predictions, and intervals
errors <- c()
forecasted_values <- c()
actual_values <- c()
lower_bounds <- c()
upper_bounds <- c()

for (i in 1:length(test_mato_grosso)) {
  # Defining training and test sets
  train_set <- log_ts[1:(train_size + i - 1)]
  test_set <- log_ts[(train_size + i):(train_size + i)]
  
  # Fitting the SARIMA model on the training set
  fit <- Arima(train_set, order = c(2, 0, 0), seasonal = c(1, 1, 0), 
                    include.constant = FALSE)
  
  # Forecasting the next value(s)
  forecast_result <- forecast(fit, h = 1)
  forecasted_value <- forecast_result$mean
  forecasted_values <- c(forecasted_values, forecasted_value)
  actual_values <- c(actual_values, test_set)
  
  # Extracting 95% confidence intervals
  lower_bound <- exp(forecast_result$lower[1, 2]) - shift_value
  upper_bound <- exp(forecast_result$upper[1, 2]) - shift_value
  lower_bounds <- c(lower_bounds, lower_bound)
  upper_bounds <- c(upper_bounds, upper_bound)
  
  # Calculating forecast error (absolute error)
  #error <- abs(forecasted_value - test_set)
  #errors <- c(errors, error)
}

actual_values = exp(actual_values) - shift_value
forecasted_values = exp(forecasted_values) - shift_value
errors = abs(forecasted_value - exp(test_set)+shift_value)
#errors = c(errors, error)

# Calculating metrics
mae <- mean(errors)
rmse <- sqrt(mean(errors^2))
mape <- mean(abs((actual_values - forecasted_values) / actual_values)) * 100
medae <- median(errors)
ss_total <- sum((actual_values - mean(actual_values))^2)
ss_residual <- sum((actual_values - forecasted_values)^2)
r_squared <- 1 - (ss_residual / ss_total)
bias <- mean(forecasted_values - actual_values)
r_squared <- 1 - (ss_residual / ss_total)
bias <- mean(forecasted_values - actual_values)
naive_forecast <- c(NA, head(actual_values, -1))  # Naive forecast: previous value
mae_naive <- mean(abs(actual_values - naive_forecast), na.rm = TRUE)  # MAE of naive forecast
mase <- mae / mae_naive


# Creating a dataframe for evaluation statistics
evaluation_df <- data.frame(
  Metric = c("MAE", "RMSE", "MAPE", "MedAE", "R-Squared", "Bias","MASE"),
  Value = c(mae, rmse, mape, medae, r_squared, bias,mase)
)

# Creating a dataframe for forecasts, intervals, and actual values
forecast_df <- data.frame(
  Date = seq(as.Date("2016-01-01"), by = "month", length.out = length(test_values)), 
  Actual = actual_values,
  Forecasted = forecasted_values,
  Lower_95 = lower_bounds,
  Upper_95 = upper_bounds,
  Inside_Interval = actual_values >= lower_bounds & actual_values <= upper_bounds,
  Error = test_values - forecast_values,  # Error: Actual - Forecast
  Absolute_Error = abs(test_values - forecast_values),  # Absolute Error
  Percentage_Error = (abs(test_values - forecast_values) / test_values) * 100  # Percentage Error
)

print("Evaluation Statistics:")
print(evaluation_df)

print("Forecast Details with 95% Intervals:")
print(forecast_df)


ggplot(forecast_df, aes(x = Date)) +
  geom_line(aes(y = log(Actual + shift_value), color = "Actual"), size = 1) +
  geom_line(aes(y = log(Forecasted + shift_value), color = "Forecast"), size = 1, linetype = "dashed") +
  geom_ribbon(aes(ymin = log(Lower_95 + shift_value), ymax = log(Upper_95 + shift_value)), fill = "lightblue", alpha = 0.5) +
  labs(
    title = "LOG SCALE: Actual vs Forecasted Values with 95% Prediction Intervals",
    x = "Date",
    y = "LOG(Number of fires)"
  ) +
  scale_color_manual(values = c("Actual" = "blue", "Forecast" = "red")) +
  theme_minimal() +
  theme(legend.title = element_blank()) 


ggplot(forecast_df, aes(x = Date)) +
  geom_line(aes(y = Actual, color = "Actual"), size = 1) +
  geom_line(aes(y = Forecasted, color = "Forecast"), size = 1, linetype = "dashed") +
  geom_ribbon(aes(ymin = Lower_95, ymax = Upper_95), fill = "lightblue", alpha = 0.5) +
  labs(
    title = "Actual vs Forecasted Values with 95% Prediction Intervals",
    x = "Date",
    y = "Number of fires"
  ) +
  scale_color_manual(values = c("Actual" = "blue", "Forecast" = "red")) +
  theme_minimal() +
  theme(legend.title = element_blank()) 


ggplot(forecast_df, aes(x = Date)) +
  geom_line(aes(y = Actual, color = "Actual"), size = 1) +
  geom_line(aes(y = Forecasted, color = "Forecast"), size = 1, linetype = "dashed") +
  labs(
    title = "Actual vs Forecasted Values with 95% Prediction Intervals",
    x = "Date",
    y = "Number of fires"
  ) +
  scale_color_manual(values = c("Actual" = "blue", "Forecast" = "red")) +
  theme_minimal() +
  theme(legend.title = element_blank()) 

```


CROSS-VALIDATION 23 months with 1-step ahead - Recursive window


```{r}
#Applying log for original data
shift_value <- 1 - min(ts_mato_grosso)
ts_mato_grosso_shifted <- ts_mato_grosso + shift_value
log_ts <- log(ts_mato_grosso_shifted)

# Setting the size of the training and test set
train_size <- length(log_ts) - length(test_mato_grosso)  

# Storing the forecast errors, predictions, and intervals
errors <- c()
forecasted_values <- c()
actual_values <- c()
lower_bounds <- c()
upper_bounds <- c()

for (i in 1:length(test_mato_grosso)) {
  # Defining training and test sets
  train_set <- log_ts[i:(train_size + i - 1)]
  test_set <- log_ts[(train_size + i):(train_size + i)]
  
  # Fitting the SARIMA model on the training set
  fit <- Arima(train_set, order = c(2, 0, 0), seasonal = c(1, 1, 0), 
                    include.constant = FALSE)
  
  # Forecasting the next value(s)
  forecast_result <- forecast(fit, h = 1)
  forecasted_value <- forecast_result$mean
  forecasted_values <- c(forecasted_values, forecasted_value)
  actual_values <- c(actual_values, test_set)
  
  # Extracting 95% confidence intervals
  lower_bound <- exp(forecast_result$lower[1, 2]) - shift_value
  upper_bound <- exp(forecast_result$upper[1, 2]) - shift_value
  lower_bounds <- c(lower_bounds, lower_bound)
  upper_bounds <- c(upper_bounds, upper_bound)
  
  # Calculating forecast error (absolute error)
  #error <- abs(forecasted_value - test_set)
  #errors <- c(errors, error)
}

actual_values = exp(actual_values) - shift_value
forecasted_values = exp(forecasted_values) - shift_value
errors = abs(forecasted_value - exp(test_set)+shift_value)
#errors = c(errors, error)

# Calculating metrics
mae <- mean(errors)
rmse <- sqrt(mean(errors^2))
mape <- mean(abs((actual_values - forecasted_values) / actual_values)) * 100
medae <- median(errors)
ss_total <- sum((actual_values - mean(actual_values))^2)
ss_residual <- sum((actual_values - forecasted_values)^2)
r_squared <- 1 - (ss_residual / ss_total)
bias <- mean(forecasted_values - actual_values)
r_squared <- 1 - (ss_residual / ss_total)
bias <- mean(forecasted_values - actual_values)
naive_forecast <- c(NA, head(actual_values, -1))  # Naive forecast: previous value
mae_naive <- mean(abs(actual_values - naive_forecast), na.rm = TRUE)  # MAE of naive forecast
mase <- mae / mae_naive


# Creating a dataframe for evaluation statistics
evaluation_df <- data.frame(
  Metric = c("MAE", "RMSE", "MAPE", "MedAE", "R-Squared", "Bias","MASE"),
  Value = c(mae, rmse, mape, medae, r_squared, bias,mase)
)

# Creating a dataframe for forecasts, intervals, and actual values
forecast_df <- data.frame(
  Date = seq(as.Date("2016-01-01"), by = "month", length.out = length(test_values)), 
  Actual = actual_values,
  Forecasted = forecasted_values,
  Lower_95 = lower_bounds,
  Upper_95 = upper_bounds,
  Inside_Interval = actual_values >= lower_bounds & actual_values <= upper_bounds,
  Error = test_values - forecast_values,  # Error: Actual - Forecast
  Absolute_Error = abs(test_values - forecast_values),  # Absolute Error
  Percentage_Error = (abs(test_values - forecast_values) / test_values) * 100  # Percentage Error
)

print("Evaluation Statistics:")
print(evaluation_df)

print("Forecast Details with 95% Intervals:")
print(forecast_df)


ggplot(forecast_df, aes(x = Date)) +
  geom_line(aes(y = log(Actual + shift_value), color = "Actual"), size = 1) +
  geom_line(aes(y = log(Forecasted + shift_value), color = "Forecast"), size = 1, linetype = "dashed") +
  geom_ribbon(aes(ymin = log(Lower_95 + shift_value), ymax = log(Upper_95 + shift_value)), fill = "lightblue", alpha = 0.5) +
  labs(
    title = "LOG SCALE: Actual vs Forecasted Values with 95% Prediction Intervals",
    x = "Date",
    y = "LOG(Number of fires)"
  ) +
  scale_color_manual(values = c("Actual" = "blue", "Forecast" = "red")) +
  theme_minimal() +
  theme(legend.title = element_blank()) 


ggplot(forecast_df, aes(x = Date)) +
  geom_line(aes(y = Actual, color = "Actual"), size = 1) +
  geom_line(aes(y = Forecasted, color = "Forecast"), size = 1, linetype = "dashed") +
  geom_ribbon(aes(ymin = Lower_95, ymax = Upper_95), fill = "lightblue", alpha = 0.5) +
  labs(
    title = "Actual vs Forecasted Values with 95% Prediction Intervals",
    x = "Date",
    y = "Number of fires"
  ) +
  scale_color_manual(values = c("Actual" = "blue", "Forecast" = "red")) +
  theme_minimal() +
  theme(legend.title = element_blank()) 


ggplot(forecast_df, aes(x = Date)) +
  geom_line(aes(y = Actual, color = "Actual"), size = 1) +
  geom_line(aes(y = Forecasted, color = "Forecast"), size = 1, linetype = "dashed") +
  labs(
    title = "Actual vs Forecasted Values with 95% Prediction Intervals",
    x = "Date",
    y = "Number of fires"
  ) +
  scale_color_manual(values = c("Actual" = "blue", "Forecast" = "red")) +
  theme_minimal() +
  theme(legend.title = element_blank()) 
```


Experiments on Cross-validation: changing the test-size
Tried from 2 to 5, unfortunately it didn't improve the performance, so it was not included into final report. The shift of the pick in the forecast may be happening just because of the training data (there the pick was either in August or September and the model just predicts the wrong month because of historical data)

```{r}

shift_value <- 1 - min(ts_mato_grosso)
ts_mato_grosso_shifted <- ts_mato_grosso + shift_value
log_ts <- log(ts_mato_grosso_shifted)


train_size <- length(log_ts) - length(test_mato_grosso)  

# Forecast horizon (h = k)
k <- 2

for (k in 2:5){
  errors <- c()
  forecasted_values <- c()
  actual_values <- c()
  lower_bounds <- c()
  upper_bounds <- c()
  
  for (i in 1:(length(test_mato_grosso) - (k - 1))) {  
    # Defining training and test sets
    train_set <- log_ts[1:(train_size + i - 1)]
    test_set <- log_ts[(train_size + i):(train_size + i + (k - 1))]  # k-step test set
    
    # Fitting the SARIMA model on the training set
    fit <- Arima(train_set, order = c(2, 0, 0), seasonal = c(1, 1, 0), 
                      include.constant = FALSE)
    
    # Forecasting the next k values
    forecast_result <- forecast(fit, h = k)
    forecasted_value <- forecast_result$mean[k]  # Extract the k-th step forecast
    forecasted_values <- c(forecasted_values, forecasted_value)
    actual_values <- c(actual_values, test_set[k])  # Add the k-th test value
    
    # Extracting 95% confidence intervals for the k-th step
    lower_bound <- exp(forecast_result$lower[k, 2]) - shift_value
    upper_bound <- exp(forecast_result$upper[k, 2]) - shift_value
    lower_bounds <- c(lower_bounds, lower_bound)
    upper_bounds <- c(upper_bounds, upper_bound)
    
    # Calculating forecast error (absolute error)
    #errors <- c(errors, abs(forecasted_value - test_set[k]))
  }
  
  
  actual_values <- exp(actual_values) - shift_value
  forecasted_values <- exp(forecasted_values) - shift_value
  errors <- abs(forecasted_values - actual_values)
  
  # Print results
  
  mae <- mean(errors)
  rmse <- sqrt(mean(errors^2))
  mape <- mean(abs((actual_values - forecasted_values) / actual_values)) * 100
  medae <- median(errors)
  ss_total <- sum((actual_values - mean(actual_values))^2)
  ss_residual <- sum((actual_values - forecasted_values)^2)
  r_squared <- 1 - (ss_residual / ss_total)
  bias <- mean(forecasted_values - actual_values)
  
  
  naive_forecast <- c(rep(NA, k), head(actual_values, -(k)))  # Shifted by k steps
  mae_naive <- mean(abs(actual_values - naive_forecast), na.rm = TRUE)  # MAE for naive
  mase <- mae / mae_naive
  
  
  evaluation_df <- data.frame(
    Metric = c("MAE", "RMSE", "MAPE", "MedAE", "R-Squared", "Bias", "MASE"),
    Value = c(mae, rmse, mape, medae, r_squared, bias, mase)
  )
  
  
  forecast_df <- data.frame(
    Date = seq(as.Date("2016-01-01"), by = "month", length.out = length(actual_values)),  
    Actual = actual_values,
    Forecasted = forecasted_values,
    Lower_95 = lower_bounds,
    Upper_95 = upper_bounds,
    Inside_Interval = actual_values >= lower_bounds & actual_values <= upper_bounds,
    Error = actual_values - forecasted_values,  # Error: Actual - Forecast
    Absolute_Error = abs(actual_values - forecasted_values),  # Absolute Error
    Percentage_Error = (abs(actual_values - forecasted_values) / actual_values) * 100  # Percentage Error
  )
  
  cat("k = ", as.character(k))
  cat("\n")
  print("Evaluation Statistics:")
  print(evaluation_df)
  
  
  print("Forecast Details with 95% Intervals:")
  print(forecast_df)
  
  
  ggplot(forecast_df, aes(x = Date)) +
    geom_line(aes(y = log(Actual + shift_value), color = "Actual"), size = 1) +
    geom_line(aes(y = log(Forecasted + shift_value), color = "Forecast"), size = 1, linetype = "dashed") +
    geom_ribbon(aes(ymin = log(Lower_95 + shift_value), ymax = log(Upper_95 + shift_value)), fill = "lightblue", alpha = 0.5) +
    labs(
      title = "LOG SCALE: Actual vs Forecasted Values with 95% Prediction Intervals",
      x = "Date",
      y = "LOG(Number of fires)"
    ) +
    scale_color_manual(values = c("Actual" = "blue", "Forecast" = "red")) +
    theme_minimal() +
    theme(legend.title = element_blank())
  
  
  ggplot(forecast_df, aes(x = Date)) +
    geom_line(aes(y = Actual, color = "Actual"), size = 1) +
    geom_line(aes(y = Forecasted, color = "Forecast"), size = 1, linetype = "dashed") +
    geom_ribbon(aes(ymin = Lower_95, ymax = Upper_95), fill = "lightblue", alpha = 0.5) +
    labs(
      title = "Actual vs Forecasted Values with 95% Prediction Intervals",
      x = "Date",
      y = "Number of fires"
    ) +
    scale_color_manual(values = c("Actual" = "blue", "Forecast" = "red")) +
    theme_minimal() +
    theme(legend.title = element_blank())
  
  
  ggplot(forecast_df, aes(x = Date)) +
    geom_line(aes(y = Actual, color = "Actual"), size = 1) +
    geom_line(aes(y = Forecasted, color = "Forecast"), size = 1, linetype = "dashed") +
    labs(
      title = "Actual vs Forecasted Values",
      x = "Date",
      y = "Number of fires"
    ) +
    scale_color_manual(values = c("Actual" = "blue", "Forecast" = "red")) +
    theme_minimal() +
    theme(legend.title = element_blank())
}
```
